{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "X, y = df.drop('Sales', axis=\"columns\"), df['Sales']\n",
    "\n",
    "model_polynomial = PolynomialFeatures(3, include_bias=False)\n",
    "poly_feature = model_polynomial.fit_transform(X)\n",
    "# poly_feature #innehåller våra features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_feature, y, test_size=0.33, random_state=1337)\n",
    "X_train.shape\n",
    "\n",
    "# eftersom vi gör regularisering, måste vi göra standardisering, nästa steg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.000, 0.031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train) # på train datan, gör både fit och transform\n",
    "scaled_X_test = scaler.transform(X_test) # på test datan, gör bara transform\n",
    "\n",
    "print(f\"{scaled_X_train.mean():.3f}, {scaled_X_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.60232255e+00  7.76137111e-01  4.08021864e-01 -6.57597265e+00\n",
      "  4.34278763e+00 -9.82498935e-01 -7.30657923e-01  1.63143459e-01\n",
      " -4.82682624e-01  2.84024955e+00 -1.33057802e+00  6.19651985e-01\n",
      "  8.33426629e-01 -3.84522734e-01  4.20534037e-01 -1.29689124e-01\n",
      "  1.92356595e-01  1.66660560e-01 -4.67542299e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24959538036150153, 0.49959521651182925)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nu ska vi göra ridge regression, \"L2 regularization\"\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "model_ridge = Ridge(alpha=0.1)\n",
    "model_ridge.fit(scaled_X_train, y_train) # tränar modellen\n",
    "y_hat = model_ridge.predict(scaled_X_test) # gör prediction på den scaled test datan\n",
    "print(model_ridge.coef_)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_hat)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "MSE, RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regressionen ger ett mycket bättre resultat, än den vi gjorde i 00!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.77053674  0.16177077  0.         -0.          3.77413423  0.\n",
      "  0.          0.04720898  0.         -0.37585383 -0.         -0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7738198161795438"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_lasso = Lasso(alpha = 0.1)\n",
    "model_lasso.fit(scaled_X_train, y_train)\n",
    "y_hat = model_lasso.predict(scaled_X_test)\n",
    "\n",
    "print(model_lasso.coef_)\n",
    "np.sqrt(mean_squared_error(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation och hyperparametrisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.34985134   0.6331339    0.4575767  -10.6664558    4.69979729\n",
      "  -1.21795087  -0.33002651  -0.2049405   -0.18235904   5.19374784\n",
      "  -1.37857412   1.00487749   0.51536908  -0.39391912   0.23265959\n",
      "  -0.28009281   0.38741237   0.14013473  -0.09899025] \n",
      " 0.9912715899638569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "model_ridgeCV = RidgeCV(alphas=[.0001, .001, .01, .1, 1, 5, 10], scoring=\"neg_mean_squared_error\")\n",
    "model_ridgeCV.fit(scaled_X_train, y_train)\n",
    "print(model_ridgeCV.coef_,  \"\\n\",  model_ridgeCV.score(scaled_X_train, y_train)) # score: hög sådan här betyder att variansen i y kan förklaras...\n",
    "model_ridgeCV.alpha_ # ger oss svaret på crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha (lambda) = 0.004956246150210799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4529065286091838"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model_lassoCV = LassoCV(eps=0.001, n_alphas=100, max_iter=10000, cv=5)\n",
    "model_lassoCV.fit(scaled_X_train, y_train)\n",
    "print(f\"alpha (lambda) = {model_lassoCV.alpha_}\")\n",
    "y_hat = model_lassoCV.predict(scaled_X_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic\n",
    "- metoden testar alla alternativen i l1_ratio. Svaret 1.0 innebär att det är bara Lasso (tror jag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0, 0.004956246150210799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "model_elastic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps=0.001, n_alphas=100, max_iter=10000, cv=5) #l1_ratio är ration mellan de två metoderna, eps är typ steglängden i iterationen\n",
    "model_elastic.fit(scaled_X_train, y_train) # tränar modellen\n",
    "print(f\"{model_elastic.l1_ratio_}, {model_elastic.alpha_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558480162209294"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model_elastic.predict(scaled_X_test)\n",
    "np.sqrt(mean_absolute_error(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning_Daniel_Claesson-bhjbabyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
